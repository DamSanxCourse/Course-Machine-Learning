{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-S7c9kFiZkyx"},"source":["## Sparse solutions with L1 regularization"]},{"cell_type":"code","metadata":{"id":"LGzJJKlVM4o1","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","import pandas as pd\n","from io import StringIO\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","import copy\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.base import clone\n","from itertools import combinations\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.base import clone\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPemfAb2Njqg","colab_type":"code","colab":{}},"source":["df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n","df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n","\n","# assign data to X, Y\n","X = df_wine.iloc[:130, 1:].values\n","y = df_wine.iloc[:130, 0].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n","\n","# Standardization\n","stdsc = StandardScaler()\n","X_train_std = stdsc.fit_transform(X_train)\n","X_test_std = stdsc.transform(X_test)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"uC4irztTNMqR","colab_type":"code","colab":{},"tags":[]},"source":["lamda = 40\n","\n","lr = LogisticRegression(penalty='l1', C=1.0/lamda, solver='liblinear')\n","lr.fit(X_train_std, y_train)\n","\n","print('Training accuracy:', lr.score(X_train_std, y_train))\n","print('Test accuracy:', lr.score(X_test_std, y_test), '\\n')\n","print(lr.coef_)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"Training accuracy: 0.9326923076923077\nTest accuracy: 0.8846153846153846 \n\n[[ 0.         0.         0.         0.         0.         0.\n   0.         0.         0.         0.         0.         0.\n  -0.1784056]]\n"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jow7RitobROk"},"source":["## Sequential feature selection algorithms"]},{"cell_type":"code","metadata":{"id":"xakcZwpBbULt","colab_type":"code","colab":{}},"source":["class SBS():\n","  def __init__(self, estimator, k_features, test_size):\n","    self.estimator = clone(estimator)     # e.g: knn\n","    self.k_features = k_features          # desired number of features\n","    self.test_size = test_size            # default: 25% data in the test set\n","\n","  def fit(self, X, y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state = 1)           # split data to train set and test set, random_state makes sure the spliting is fixed in every run. \n","    dim = X_train.shape[1]                                                            # number of features of the original data set (13)\n","    self.indices_ = tuple(range(dim))                                                 # the column indices of the fnal feature subset (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n","    self.subsets_ = [self.indices_]                                                   # [(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)]\n","    score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)         # score of model have all features\n","    self.scores_ = [score]                                                            # score of model have all features\n","  \n","    while dim > self.k_features:\n","      scores = []\n","      subsets = []\n","      for p in combinations(self.indices_, r=dim - 1):                # (r-1) subsets of r features, where number of features of each subset is (r-1)\n","        score = self._calc_score(X_train, y_train,X_test, y_test, p)  # calculate score of a subset\n","        scores.append(score)                                          # array of (r-1) score of (r-1) subsets, e.g: [0.3, 0.5, 0.9, 0.8, 0.99]\n","        subsets.append(p)                                             # array of (r-1) subsets of r features, e.g: [(0,1), (0,2), (1,2)]\n","      best = np.argmax(scores)                                        # return the index of the greatest score of a combination, e.g: 9\n","      self.indices_ = subsets[best]                                   # return best subset and overwrite in indices_, e.g: (1,2)\n","      self.subsets_.append(self.indices_)                             # append best subset to array subsets_, e.g: [(1,2,3,4), (1,3,4), (1,3)]\n","      dim -= 1                                                        # dim = dim - 1\n","      self.scores_.append(scores[best])                               # append score of best subsets to array scores_\n","    return self\n","\n","  def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n","    self.estimator.fit(X_train[:, indices], y_train)\n","    y_pred = self.estimator.predict(X_test[:, indices])\n","    score = accuracy_score(y_test, y_pred)\n","    return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yjl8lPE0caWI","colab_type":"code","colab":{}},"source":["knn = KNeighborsClassifier(n_neighbors=5)                   # object knn with n_neighbors = 5\n","sbs = SBS(estimator=knn, k_features=1, test_size=0.25)      # object sbs\n","sbs.fit(X_train_std, y_train)                               # train model, return subsets_, scores_\n","sbs.subsets_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aicDtqQHdNyp","colab_type":"code","colab":{}},"source":["k_feat = [len(k) for k in sbs.subsets_]\n","plt.plot(k_feat, sbs.scores_, marker='o')\n","plt.ylim([0.7, 1.01])\n","plt.ylabel('Accuracy')\n","plt.xlabel('Number of features')\n","plt.grid()\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2MP8drDdb0C","colab_type":"code","colab":{},"tags":[]},"source":["d_k = 7\n","\n","k = list(sbs.subsets_[13-d_k])\n","print('selected features: ', df_wine.columns[1:][k])\n","\n","knn.fit(X_train_std, y_train)\n","print('\\nTraining accuracy of all features:', knn.score(X_train_std, y_train))\n","print('Test accuracy of all features:', knn.score(X_test_std, y_test))\n","\n","knn.fit(X_train_std[:, k], y_train)\n","print('\\nTraining accuracy of' , d_k , 'features :', knn.score(X_train_std[:, k], y_train))\n","print('Test accuracy of', d_k , 'features :', knn.score(X_test_std[:, k], y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sjCJcUfAc5-A","colab_type":"text"},"source":["## Assessing feature importance with random forests"]},{"cell_type":"code","metadata":{"id":"2bWTT-uqc8vv","colab_type":"code","colab":{}},"source":["feat_labels = df_wine.columns[1:]\n","forest = RandomForestClassifier(n_estimators=500, random_state=1)\n","forest.fit(X_train, y_train)\n","importances = forest.feature_importances_\n","indices = np.argsort(importances)[::-1]\n","for f in range(X_train.shape[1]):\n","  print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n","\n","importances\n","indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNfV1074fwt4","colab_type":"code","colab":{}},"source":["plt.title('Feature Importance')\n","plt.bar(range(X_train.shape[1]), importances[indices], align='center')\n","plt.xticks(range(X_train.shape[1]), feat_labels[indices], rotation=90)\n","plt.xlim([-1, X_train.shape[1]])\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"07_selecting meaningful features.ipynb","provenance":[],"collapsed_sections":["-S7c9kFiZkyx","Jow7RitobROk","sjCJcUfAc5-A"],"authorship_tag":"ABX9TyONenDNFs/UQbzz1T3oLEdB"},"kernelspec":{"name":"python_defaultSpec_1594909483020","display_name":"Python 3.8.3 64-bit"}},"nbformat":4,"nbformat_minor":0}